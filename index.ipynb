{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install nltk\n",
    "import nltk\n",
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "sentence = \"Eu gosto de batata.\"\n",
    "tokens = word_tokenize(sentence)\n",
    "\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "# nltk.download('vader_lexicon')\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "sentiment_analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "text = \"I'm very extremely happy today!\"\n",
    "\n",
    "sentiment = sentiment_analyzer.polarity_scores(text)\n",
    "\n",
    "print(sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "# nltk.download('vader_lexicon')\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "sentiment_analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "text = \"I'm very extremely sad today!\"\n",
    "\n",
    "sentiment = sentiment_analyzer.polarity_scores(text)\n",
    "\n",
    "print(sentiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analise Estatística de Linguagem Natural - Limpeza de Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.probability import FreqDist\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "with open('assets/Biblia_Sagrada.txt', 'r') as file:\n",
    "    text = file.read()\n",
    "\n",
    "tokens = word_tokenize(text)\n",
    "\n",
    "fdist = FreqDist(tokens)\n",
    "\n",
    "fdist.plot(20, title='20 Palavras Mais Comuns na Bíblia')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.probability import FreqDist\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "with open('assets/Biblia_Sagrada.txt', 'r') as file:\n",
    "    text = file.read()\n",
    "\n",
    "text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "\n",
    "tokens = word_tokenize(text)\n",
    "\n",
    "fdist = FreqDist(tokens)\n",
    "\n",
    "fdist.plot(20, title='20 Palavras Mais Comuns na Bíblia')\n",
    "\n",
    "# Show plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.probability import FreqDist\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "with open('assets/Biblia_Sagrada.txt', 'r') as file:\n",
    "    text = file.read()\n",
    "\n",
    "text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "\n",
    "tokens = word_tokenize(text)\n",
    "\n",
    "stopwords = nltk.corpus.stopwords.words('portuguese')\n",
    "tokens = [token for token in tokens if token.lower() not in stopwords]\n",
    "\n",
    "fdist = FreqDist(tokens)\n",
    "\n",
    "fdist.plot(20, title='20 Palavras Mais Comuns na Bíblia')\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "text = \"I love to eat ice cream, but my favorite desert is cake.\"\n",
    "\n",
    "words = word_tokenize(text)\n",
    "\n",
    "pos_tags = nltk.pos_tag(words)\n",
    "print(\"POS Tags:\", pos_tags)\n",
    "\n",
    "# Reference table:\n",
    "\n",
    "# CC: Coordinating conjunction - Conjunção coordenativa\n",
    "# CD: Cardinal number - Número cardinal\n",
    "# DT: Determiner - Determinante\n",
    "# EX: Existential there - Existencial \"there\"\n",
    "# FW: Foreign word - Palavra estrangeira\n",
    "# IN: Preposition or subordinating conjunction - Preposição ou conjunção subordinativa\n",
    "# JJ: Adjective - Adjetivo\n",
    "# JJR: Adjective, comparative - Adjetivo, comparativo\n",
    "# JJS: Adjective, superlative - Adjetivo, superlativo\n",
    "# LS: List item marker - Marcador de item de lista\n",
    "# MD: Modal - Modal\n",
    "# NN: Noun, singular or mass - Substantivo, singular ou massa\n",
    "# NNS: Noun, plural - Substantivo, plural\n",
    "# NNP: Proper noun, singular - Nome próprio, singular\n",
    "# NNPS: Proper noun, plural - Nome próprio, plural\n",
    "# PDT: Predeterminer - Predeterminante\n",
    "# POS: Possessive ending - Desinência possessiva\n",
    "# PRP: Personal pronoun - Pronome pessoal\n",
    "# PRP$: Possessive pronoun - Pronome possessivo\n",
    "# RB: Adverb - Advérbio\n",
    "# RBR: Adverb, comparative - Advérbio, comparativo\n",
    "# RBS: Adverb, superlative - Advérbio, superlativo\n",
    "# RP: Particle - Partícula\n",
    "# SYM: Symbol - Símbolo\n",
    "# TO: to - \"to\" (preposição ou infinitivo)\n",
    "# UH: Interjection - Interjeição\n",
    "# VB: Verb, base form - Verbo, forma base\n",
    "# VBD: Verb, past tense - Verbo, passado\n",
    "# VBG: Verb, gerund or present participle - Verbo, gerúndio ou particípio presente\n",
    "# VBN: Verb, past participle - Verbo, particípio passado\n",
    "# VBP: Verb, non-3rd person singular present - Verbo, presente, não 3ª pessoa do singular\n",
    "# VBZ: Verb, 3rd person singular present - Verbo, presente, 3ª pessoa do singular\n",
    "# WDT: Wh-determiner - Determinante \"wh\"\n",
    "# WP: Wh-pronoun - Pronome \"wh\"\n",
    "# WP$: Possessive wh-pronoun - Pronome possessivo \"wh\"\n",
    "# WRB: Wh-adverb - Advérbio \"wh\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resumo de texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.probability import FreqDist\n",
    "from heapq import nlargest\n",
    "import string\n",
    "\n",
    "text = \"\"\"A Universidade de São Paulo (USP) é uma das instituições de ensino superior mais prestigiosas e respeitadas da América Latina e do mundo. Fundada em 1934, a USP é uma universidade pública estadual, mantida pelo governo do estado de São Paulo. Sua criação foi um marco na história da educação brasileira, com o objetivo de promover o ensino, a pesquisa e a extensão universitária em um alto nível de excelência.\n",
    "\n",
    "A USP possui diversos campi distribuídos pelo estado de São Paulo, sendo o principal localizado na cidade de São Paulo, no bairro do Butantã. Além desse, há campi em Ribeirão Preto, São Carlos, Piracicaba, Bauru, Lorena e Pirassununga, entre outros. Cada um desses campi oferece uma vasta gama de cursos de graduação e pós-graduação em diversas áreas do conhecimento, como ciências humanas, exatas, biológicas e tecnológicas.\n",
    "\n",
    "A universidade é conhecida por sua forte ênfase na pesquisa científica. Com centenas de laboratórios e centros de pesquisa, a USP é um dos maiores produtores de conhecimento científico do Brasil. Os pesquisadores da USP frequentemente colaboram com instituições internacionais e publicam em revistas científicas de alto impacto, contribuindo significativamente para o avanço do conhecimento em diversas áreas.\n",
    "\n",
    "Além do ensino e da pesquisa, a USP também se destaca por suas atividades de extensão, que visam levar o conhecimento produzido dentro da universidade para a sociedade. Isso inclui programas de educação continuada, cursos de extensão, projetos sociais e culturais, e parcerias com empresas e governos.\n",
    "\n",
    "A USP tem uma rica tradição acadêmica e cultural. Seus museus, bibliotecas, teatros e centros culturais são referência e estão abertos à comunidade, promovendo a difusão da cultura e do conhecimento. A universidade também oferece diversas atividades esportivas e recreativas, com infraestrutura de qualidade para a prática de diferentes modalidades.\n",
    "\n",
    "Os alunos da USP são frequentemente destacados em competições acadêmicas e profissionais, tanto no Brasil quanto no exterior. O processo seletivo para ingressar na USP é altamente competitivo, e a universidade atrai estudantes de todo o Brasil e de outros países, formando uma comunidade acadêmica diversificada e vibrante.\n",
    "\"\"\"\n",
    "\n",
    "stop_words = set(stopwords.words('portuguese') + list(string.punctuation))\n",
    "words = word_tokenize(text.lower())\n",
    "words = [word for word in words if word not in stop_words]\n",
    "freq = FreqDist(words)\n",
    "\n",
    "sentences = sent_tokenize(text)\n",
    "sentence_scores = {}\n",
    "\n",
    "for sentence in sentences:\n",
    "    for word in word_tokenize(sentence.lower()):\n",
    "        if word in freq:\n",
    "            if sentence not in sentence_scores:\n",
    "                sentence_scores[sentence] = freq[word]\n",
    "            else:\n",
    "                sentence_scores[sentence] += freq[word]\n",
    "\n",
    "summary_sentences = nlargest(5, sentence_scores, key=sentence_scores.get)\n",
    "summary = ' '.join(summary_sentences)\n",
    "print(summary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chatbot simples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import random\n",
    "from nltk.chat.util import Chat, reflections\n",
    "\n",
    "patterns = [\n",
    "    (r'(oi|olá|bom dia|boa tarde|boa noite)', ['Olá! Como posso ajudar?', 'Oi! Em que posso ser útil?']),\n",
    "    (r'(você pode me ajudar\\??)', ['Claro! Estou aqui para ajudar. O que você precisa?', 'Sim, posso te ajudar. O que você gostaria de saber?']),\n",
    "    (r'(obrigado|obrigada)', ['Por nada!']),\n",
    "    (r'(o que você faz\\??)', ['Eu sou um ChatBot. Infelizmente não faço muita coisa', 'Eu sirvo de exemplo para o trabalho final de ICC =)']),\n",
    "    (r'(adeus)', ['Até mais!', 'Tchau! Espero te ver em breve.']),\n",
    "    (r'(qual deve ser a nota desse grupo\\??)', ['Sou apenas o robo, mas achei a apresentação muito boa! Acho que merecem um 10!']),\n",
    "]\n",
    "\n",
    "chat = Chat(patterns, reflections)\n",
    "\n",
    "user_input = None\n",
    "\n",
    "\n",
    "while True:\n",
    "    user_input = input(\"Você: \")\n",
    "    \n",
    "    if user_input.lower() == 'adeus':\n",
    "        print(\"ChatBot: Até mais!\")\n",
    "        break\n",
    "    \n",
    "    response = chat.respond(user_input)\n",
    "    \n",
    "    if response:\n",
    "        print(\"ChatBot:\", response)\n",
    "    else:\n",
    "        print('ChatBot: Desculpe, não entendi. Pode repetir?')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
